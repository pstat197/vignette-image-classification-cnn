---
title: "CNN Vignette Primary Document"
author: "Kaitlyn, Oscar, Nini, Johanna"
date: "2025-12-03"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Convolutional Neural Network Vignette

## CNN vs. NN

CNN stands for Convolutional Neural Network. They are different from NNs in that CNNs use small learning filters to detect patterns that don't depend on their position in the image, whereas NNs treat all of the input features independently. CNNs are a type of NN that are specifically designed for spatial data; in this case, images. It uses 5 layers:

-   Convolutional layer

-   Pooling layer

-   Flatten layer

-   Fully-connected layer

-   Dropout layer

The convolutional layer applies learning filters that detect patterns like edges, textures, and eventually more complex features. It learns hierarchically (meaning it finds the edges and textures of objects contained in the input pictures earlier on in processing, and it recognizes shapes and objects later on).

The pooling layer extracts the features and makes the images smaller, which is more computationally efficient.

The flatten layer converts the 3D feature maps (height x width x channels) created by the convolutional and pooling layers and makes them one-dimensional. This gives us a large fully-connected layer.

The fully-connected layer is a standard NN that combines all of the features that the convolutional layers learned and makes multi-class predictions.

The dropout layer prevents overfitting by randomly setting some fractions of neurons to 0, causing the network to learn redundant representations and not rely on specific neurons.

## Example Dataset

We worked with a Kaggle dataset of 6500 butterfly images, that represented 75 different classes of the butterfly species. The training and testing data were pre-split. 

## Code Summary
### Data Loading

```{python}
train_df = pd.read_csv(TRAIN_CSV)
test_df  = pd.read_csv(TEST_CSV)
```

Here, we loaded the training and testing CSV files that contained the image filenames and their labels.

### Data Preprocessing
```{python}
train_df_split, val_df_split = train_test_split(
    train_df, test_size=0.2, stratify=train_df['class'], random_state=123
)
```

Here, we split the training data set into 80% training and 20% validation sets. 