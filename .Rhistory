countryinfo <- read_csv('country-info.csv') %>%
select(3, 6, 7) %>%
rename('Country Code' = 'alpha-3')
#View(countryinfo)
# Import and format GDP per capita
gdp <- read_csv('gdp-per-capita.csv', locale = locale(encoding = 'latin1')) %>%
select(-'Indicator Name', -'Indicator Code') %>%
pivot_longer(cols = -c('Country Name', 'Country Code'),
names_to = 'Year',
values_to = 'GDP_per_capita') %>%
mutate(Year = as.integer(Year))
# Import and format life expectancies
life <- read_csv('life-expectancy.csv') %>%
rename(Life_Expectancy = All,
Male_Life_Expectancy = Male,
Female_Life_Expectancy = Female)
#View(gdp)
#View(life)
# Import population data
pop <- read_csv('population.csv', locale = locale(encoding = 'latin1')) %>%
pivot_longer(cols = -c('Country Name', 'Country Code'),
names_to = 'Year',
values_to = 'Population') %>%
mutate(Year = as.integer(Year)) %>%
select(-c('Country Name'))
#View(pop)
# Merge data
merge1 <- left_join(life, gdp, by = c('Country Name', 'Year'))
#View(merge1)
merge2 <- left_join(merge1, countryinfo, by = 'Country Code')
merge3 <- left_join(merge2, pop, by = c('Country Code', 'Year'))
# Final data
data <- merge3 %>%
drop_na() %>%
select(-'Country Code')
# View the first few rows of the final dataset
head(data)
# Load necessary library
library(ggplot2)
# Basic scatterplot in R using ggplot2
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy)) +
geom_point() +
theme_minimal() +
labs(x = "GDP per capita", y = "Life Expectancy")
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy)) +
geom_line(shape = 17, size = 3) +  # Triangle shape
theme_minimal() +
labs(x = "GDP per capita", y = "Life Expectancy")
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy)) +
geom_jitter(shape = 17, size = 3) +  # Triangle shape
theme_minimal() +
labs(x = "GDP per capita", y = "Life Expectancy")
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy)) +
geom_point(shape = 17, size = 3) +  # Triangle shape
theme_minimal() +
labs(x = "GDP per capita", y = "Life Expectancy")
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy)) +
geom_jitter(shape = 17, size = 3) +  # Triangle shape
theme_minimal() +
labs(x = "GDP per capita", y = "Life Expectancy")
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy)) +
geom_point(shape = 17, size = 3) +  # Triangle shape
theme_minimal() +
labs(x = "GDP per capita", y = "Life Expectancy")
?geom()
?geom_point()
?geom_circle()
# change axis label
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy)) +
geom_point() +
theme_minimal() +
labs(x = "GDP per capita", y = "Life Expectancy at Birth")  # Custom y-axis title
# don't start y axis at zero
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy)) +
geom_point() +
theme_minimal() +
labs(x = "GDP per capita", y = "Life Expectancy at Birth") +
scale_y_continuous(expand = c(0, 0), limits = c(min(data$Life_Expectancy), NA))  # Remove zero from y-axis
# log scale for x axis
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy)) +
geom_point() +
theme_minimal() +
labs(x = "GDP per capita", y = "Life Expectancy at Birth") +
scale_x_log10() +  # Apply log scale to x-axis
scale_y_continuous(expand = c(0, 0), limits = c(min(data$Life_Expectancy), NA))  # Prevent y-axis from starting at zero
# try another axis scale
ggplot(data, aes(x = ... , y = Life_Expectancy)) +
geom_point() +
theme_minimal() +
labs(x = "GDP per capita", y = "Life Expectancy at Birth") +
... +  # Apply log scale to x-axis
scale_y_continuous(name = "Life Expectancy at Birth", expand = expansion(mult = c(0, 0.1)))
?ggplot2
knitr::opts_chunk$set(echo = TRUE)
pred1 <- prediction(test_prob, algae.test$a1)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ISLR)
library(ROCR)
library(knitr)
data("Auto")
Auto$origin = as.factor(Auto$origin)
auto_model <- lm(mpg ~ cylinders + displacement + horsepower + weight + acceleration + year +
origin, data = Auto)
kable(summary(auto_model)$coefficients)
set.seed(10312025)
predicted <- predict(auto_model, Auto)
training_mse <- mean((Auto$mpg - predicted)^2)
training_mse
new_car <- data.frame(
cylinders = 4,
displacement = 133,
horsepower = 117,
weight = 3250,
acceleration = 29,
year = 97,  # 1997 coded as 97
origin = as.factor(2)  # European = 2
)
predicted_new_car <- predict(auto_model, newdata = new_car)
predicted_new_car
algae <- read_table2("algaeBloom.txt", col_names=
c('season','size','speed','mxPH','mnO2','Cl','NO3','NH4',
'oPO4','PO4','Chla','a1','a2','a3','a4','a5','a6','a7'),
na="XXXXXXX")
algae.transformed <- algae %>% mutate_at(vars(4:11), funs(log(.)))
algae.transformed <- algae.transformed %>%
mutate_at(vars(4:11),funs(ifelse(is.na(.),
median(.,na.rm=TRUE),.)))
# a1 == 0 means low
algae.transformed <- algae.transformed %>%
mutate(a1 = factor(as.integer(a1 > 5), levels = c(0, 1)))
calc_error_rate <- function(predicted.value, true.value){
return(mean(true.value != predicted.value))
}
set.seed(1)
test.indices = sample(1:nrow(algae.transformed), 50)
algae.train=algae.transformed[-test.indices,]
algae.test=algae.transformed[test.indices,]
glm.fit <- glm(a1 ~ season + size + speed + mxPH + mnO2 + Cl + NO3 +
NH4 + oPO4 + PO4 + Chla, data = algae.train,
family = "binomial")
train_prob <- predict(glm.fit, algae.train, type = "response")
test_prob <- predict(glm.fit, algae.test, type="response")
train_predictions <- ifelse(train_prob > 0.5, 1, 0)
test_predictions <- ifelse(test_prob > 0.5, 1, 0)
train_error_rate <- calc_error_rate(train_predictions, algae.train$a1)
test_error_rate <- calc_error_rate(test_predictions, algae.test$a1)
train_error_rate
test_error_rate
pred1 <- prediction(test_prob, algae.test$a1)
perf1 <- performance(pred1, measure="tpr", x.measure="fpr")
plot(perf1, col=2, lwd=3, main="ROC curve")
abline(0,1)
auc1 <- performance(pred1, "auc")@y.values
auc1
library(MASS)
lda_fit <- MASS::lda(a1 ~ season + size + speed + mxPH + mnO2 + Cl + NO3 +
NH4 + oPO4 + PO4 + Chla, data = algae.train, CV = TRUE)
lda_pred <- lda_fit$posterior[, 2]
pred_lda <- prediction(lda_pred, algae.train$a1)
perf_lda <- performance(pred_lda, "tpr", "fpr")
plot(perf_lda, col=2, lwd=3, main="ROC curve")
abline(0,1)
qda_fit <- MASS::qda(a1 ~ season + size + speed + mxPH + mnO2 + Cl + NO3 +
NH4 + oPO4 + PO4 + Chla, data = algae.train, CV = TRUE)
qda_pred <- qda_fit$posterior[, 2]
pred_qda <- prediction(qda_pred, algae.train$a1)
perf_qda <- performance(pred_qda, "tpr", "fpr")
plot(perf_lda, col = "blue", lwd = 2,
main = "ROC Curves for LDA and QDA")
plot(perf_qda, col = "red", lwd = 2, add = TRUE)
abline(a = 0, b = 1)
legend("bottomright", legend = c("LDA", "QDA"), col = c("blue", "red"), lwd = 2)
auc_lda <- performance(pred_lda, "auc")@y.values
auc_lda
auc_qda <- performance(pred_qda, "auc")@y.values
auc_qda
(1-(1/1000))^1000
set.seed(1132025)
bootstrap_sample <- sample(1:1000, size = 1000, replace = TRUE)
unique_obs <- unique(bootstrap_sample)
num_missing <- 1000 - length(unique_obs)
ratio_missing <- num_missing / 1000
ratio_missing
dat = subset(Smarket, select = -c(Year,Today))
dat$Direction = ifelse(dat$Direction == "Up", 1, 0)
library(glmnet)
# Set random seed
set.seed(123)
# Sample 50% observations as training data
train_data = sample(1:nrow(dat), 700)
dat.train_data = dat[train_data,]
# The rest 50% as test data
dat.test_data = dat[-train_data,]
# logistic regression model
logistic_reg_model <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume,
data = dat.train_data,
family = "binomial")
summary(logistic_reg_model)
# Calculate error rate
test_probs = predict(logistic_reg_model, newdata = dat.test_data, type = "response")
test_predictions = ifelse(test_probs > 0.5, 1, 0)
test_error_rate = mean(test_predictions != dat.test_data$Direction)
test_error_rate
set.seed(123)
do.chunk <- function(chunkid, folddef, dat, ...){
# Get training index
train = (folddef!=chunkid)
# Get training set and validation set
dat.train = dat[train, ]
dat.val = dat[-train, ]
# Train logistic regression model on training data
fit.train = glm(Direction ~ ., family = binomial, data = dat.train)
# get predicted value on the validation set
pred.val = predict(fit.train, newdata = dat.val, type = "response")
pred.val = ifelse(pred.val > .5, 1,0)
data.frame(fold = chunkid,
val.error = mean(pred.val != dat.val$Direction))
}
folds = cut(1:nrow(dat), breaks = 10)
folds = sample(folds)
cv.results = sapply(1:10, do.chunk, folddef = folds, dat = dat)
cv.error = mean(cv.results[[2]])
cv.error
# try another axis scale
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy)) +
geom_point() +
theme_minimal() +
labs(x = "GDP per capita", y = "Life Expectancy at Birth") +
scale_x_continuous +  # Apply log scale to x-axis
scale_y_continuous(name = "Life Expectancy at Birth", expand = expansion(mult = c(0, 0.1)))
# try another axis scale
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy)) +
geom_point() +
theme_minimal() +
labs(x = "GDP per capita", y = "Life Expectancy at Birth") +
scale_x_continuous() +  # Apply log scale to x-axis
scale_y_continuous(name = "Life Expectancy at Birth", expand = expansion(mult = c(0, 0.1)))
# try another axis scale
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy)) +
geom_point() +
theme_minimal() +
labs(x = "GDP per capita", y = "Life Expectancy at Birth") +
scale_x_log10() +  # Apply log scale to x-axis
scale_y_continuous(name = "Life Expectancy at Birth", expand = expansion(mult = c(0, 0.1)))
#View(data)
# change opacity globally to fixed value
library(scales)
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy))+
geom_point(alpha = 0.5) +
scale_x_log10() +
scale_y_continuous(name = "Life Expectancy at Birth", expand = expansion(mult = c(0, 0.05)))
# use opacity as an encoding channel
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy, alpha = Year)) +
geom_point() +
scale_x_log10() +
scale_y_continuous(name = "Life Expectancy at Birth", expand = expansion(mult = c(0, 0.05))) +
theme_minimal()
data$Year <- ...
data$Year <- as.factor(data$Year)
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy, alpha = Year)) +
geom_point() +
scale_x_log10() +
scale_y_continuous(name = "Life Expectancy at Birth", expand = expansion(mult = c(0, 0.05))) +
theme_minimal() +
guides(alpha = guide_legend(title = "Year"))
# Option 1: Using scale_color_viridis_d()
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy, color = Region, shape = Region)) +
geom_point(size = 3) +
scale_x_log10() +
scale_y_continuous(name = "Life Expectancy at Birth", expand = expansion(mult = c(0, 0.05))) +
scale_color_viridis_d() +
theme_minimal()
knitr::opts_chunk$set(message =  FALSE)
knitr::opts_chunk$set(warning =  FALSE)
knitr::opts_chunk$set(error =  FALSE)
bfcolor <- function(x, color) {
if (knitr::is_latex_output()) {
sprintf("\\textcolor{%s}{\\textbf{%s}}", color, x)
} else if (knitr::is_html_output()) {
sprintf("<span style='color: %s;'><b>%s</b></span>", color, x)
} else x
}
# Install necessary libraries if they aren't installed
if (!require(dplyr)) install.packages("dplyr")
if (!require(tidyr)) install.packages("tidyr")
if (!require(ggplot2)) install.packages("ggplot2")
# Load necessary libraries
library(dplyr)
library(tidyr)
library(readr)
# Import and format country regional information
countryinfo <- read_csv('country-info.csv') %>%
select(3, 6, 7) %>%
rename('Country Code' = 'alpha-3')
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy, color = Year, shape = Year)) +
geom_point(size = 3) +
scale_x_log10() +
scale_y_continuous(name = "Life Expectancy at Birth", expand = expansion(mult = c(0, 0.05))) +
scale_color_discrete() +
theme_minimal()
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy, color = Year, shape = "diamond")) +
geom_point(size = 3) +
scale_x_log10() +
scale_y_continuous(name = "Life Expectancy at Birth", expand = expansion(mult = c(0, 0.05))) +
scale_color_viridis_d(alpha = 0.8) +
theme_minimal()
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy, color = Year, shape = "cross")) +
geom_point(size = 3) +
scale_x_log10() +
scale_y_continuous(name = "Life Expectancy at Birth", expand = expansion(mult = c(0, 0.05))) +
scale_color_brewer(palette = "Set2") +
theme_minimal()
# Option 1: Using scale_color_viridis_d()
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy, color = Region, shape = Region)) +
geom_point(size = 3) +
scale_x_log10() +
scale_y_continuous(name = "Life Expectancy at Birth", expand = expansion(mult = c(0, 0.05))) +
scale_color_viridis_d(alpha = 0.8) +
theme_minimal()
# Option 1: Using scale_color_viridis_d()
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy, color = Region, shape = "plus")) +
geom_point(size = 3) +
scale_x_log10() +
scale_y_continuous(name = "Life Expectancy at Birth", expand = expansion(mult = c(0, 0.05))) +
scale_color_viridis_d(alpha = 0.8) +
theme_minimal()
# map population to size
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy, color = region, size = Population)) +
geom_point(alpha = 0.5) +
scale_x_log10() +
scale_y_continuous(name = "Life Expectancy at Birth",expand = expansion(mult = c(0, 0.07))) +
scale_color_brewer(name = "Region",palette = "Set2") +
scale_size_continuous(name = "Population") +
theme_minimal()
# rescale size
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy, color = region, size = Population)) +
geom_point(alpha = 0.5) +
scale_x_log10() +
scale_y_continuous(name = "Life Expectancy at Birth",expand = expansion(mult = c(0, 0.07))) +
scale_color_brewer(name = "Region",palette = "Set2") +
scale_size_continuous(trans = "sqrt",name = "Population") +
theme_minimal()
# facet by year
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy, color = region, size = Population)) +
geom_point(alpha = 0.5) +
scale_x_log10() +
scale_y_continuous(name = "Life Expectancy at Birth", expand = expansion(mult = c(0, 0.07))) +
scale_size_continuous(trans = "sqrt", guide = guide_legend(title = "Population")) +
theme_minimal() +
guides(color = guide_legend(title = "Region")) +
facet_wrap(~ Year, ncol = 1)  # Adjust the number of columns if needed
# Option 1: Using scale_color_viridis_d()
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy, color = region, shape = "plus")) +
geom_point(size = 3) +
scale_x_log10() +
scale_y_continuous(name = "Life Expectancy at Birth", expand = expansion(mult = c(0, 0.05))) +
scale_color_viridis_d(alpha = 0.8) +
theme_minimal()
# Option 2: Using scale_color_brewer()
ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy, color = region, shape = "square")) +
geom_point(size = 3) +
scale_x_log10() +
scale_y_continuous(name = "Life Expectancy at Birth", expand = expansion(mult = c(0, 0.05))) +
scale_color_brewer(palette = "Set2") +
theme_minimal()
# resize facets
# Create the faceted plot
p <- ggplot(data, aes(x = GDP_per_capita, y = Life_Expectancy, color = region, size = Population)) +
geom_point(alpha = 0.5) +
scale_x_log10() +
scale_y_continuous(name = "Life Expectancy at Birth", expand = expansion(mult = c(0, 0.07))) +
scale_size_continuous(trans = "sqrt", guide = guide_legend(title = "Population")) +
theme_minimal() +
guides(color = guide_legend(title = "Region")) +
facet_wrap(~ Year) +
theme(
panel.spacing = unit(1, "lines"),      # Adjust space between facets
aspect.ratio = 1                    # Adjust aspect ratio of individual facets
)
p
# Save the plot with specific dimensions
#ggsave("faceted_plot.png", plot = p, width = 12, height = 8)
knitr::opts_chunk$set(echo=TRUE,
cache=FALSE,
fig.width=5,
fig.height=5,
fig.align='center')
indent1 = '    '
indent2 = paste(rep(indent1, 2), collapse='')
solcode = TRUE
r = function(x, digits=2){ round(x, digits=digits) }
install.packages("ISLR")
install.packages("tree")
install.packages('maptree')
install.packages("ISLR")
# Load libraries
library(ISLR)
library(tree)
library(maptree)
# Utility library
library(dplyr)
# Create data frame with the oringinal eleven variables and High
Carseats = Carseats %>%
mutate(High=as.factor(ifelse(Sales <= median(Sales), "No", "Yes")))
# Check the structure of above data frame we just created
glimpse(Carseats)
tree.carseats = tree(High ~.-Sales, data = Carseats)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats, pretty = 0, cex = .4, col = "red")
title("decision tree on Carseats", cex = 0.8)
draw.tree(tree.carseats, nodeinfo=TRUE, cex = 0.4)
# Set random seed for results being reproducible
set.seed(3)
# Get dimension of dataset
dim(Carseats)
# Sample 75% of observations as the training set
train = sample(nrow(Carseats), 0.75*nrow(Carseats))
Carseats.train = Carseats[train, ]
# The rest 25% as the test set
Carseats.test = Carseats[-train,]
# For later convenience in coding, we create High.test, which is the true labels of the
# test cases
High.test = Carseats.test$High
# Fit model on training set
tree.carseats = tree(High~.-Sales, data = Carseats.train)
# Plot the tree
draw.tree(tree.carseats, nodeinfo=TRUE, cex = 0.4)
title("Classification Tree Built on Training Set")
# Predict on test set
tree.pred = predict(tree.carseats, Carseats.test, type="class")
tree.pred
mean(tree.pred != High.test)
# Obtain confusion matrix
error = table(tree.pred, High.test)
error
# Test accuracy rate
sum(diag(error))/sum(error)
# Test error rate (Classification Error)
1-sum(diag(error))/sum(error)
# Set random seed
set.seed(3)
# K-Fold cross validation
cv = cv.tree(tree.carseats, FUN=prune.misclass, K=10)
# Print out cv
cv$size
cv$dev
# Best size
# note that there is a tie
# tree of size 21 and size 16 both have the minimum CV estimate of test error rate
# we prefer the tree with smaller size
best.cv = min(cv$size[cv$dev == min(cv$dev)])
best.cv
# Plot size vs. cross-validation error rate
plot(cv$size , cv$dev, type="b",
xlab = "Number of leaves, \'best\'", ylab = "CV Misclassification Error",
col = "red", main="CV")
abline(v=best.cv, lty=2)
# Add lines to identify complexity parameter
min.error = which.min(cv$dev) # Get minimum error index
abline(h = cv$dev[min.error],lty = 2)
# Prune tree.carseats
pt.cv = prune.misclass(tree.carseats, best=best.cv)
# Plot pruned tree
plot(pt.cv)
text(pt.cv, pretty=0, col = "blue", cex = .5)
title("Pruned tree of size 16")
# Predict on test set
pred.pt.cv = predict(pt.cv, Carseats.test, type="class")
# Obtain confusion matrix
err.pt.cv = table(pred.pt.cv, High.test)
err.pt.cv
# Test accuracy rate
sum(diag(err.pt.cv))/sum(err.pt.cv)
# Test error rate (Classification Error)
1-sum(diag(err.pt.cv))/sum(err.pt.cv)
# Codes start here
set.seed(1162025)
# Perform 5-fold cross-validation
cv_carseats <- cv.tree(tree.carseats, FUN = prune.misclass, K = 5)
# View CV results
cv_carseats
# Plot cross-validation error vs tree size
plot(cv_carseats$size, cv_carseats$dev, type = "b",
xlab = "Tree Size (Number of Terminal Nodes)",
ylab = "Cross-Validation Error",
main = "Cross-Validation Error vs Tree Size")
# Find the best tree size (minimum CV error)
best_size <- cv_carseats$size[which.min(cv_carseats$dev)]
cat("Best tree size:", best_size, "\n")
# Prune the tree to the best size
pruned_tree <- prune.misclass(tree.carseats, best = best_size)
# Plot the pruned tree
plot(pruned_tree)
text(pruned_tree, pretty = 0)
title(paste("Pruned Tree with", best_size, "Terminal Nodes"))
# Codes start here:
# Test set is Carseats.test
# Predict on test set
tree_pred <- predict(pruned_tree, Carseats.test, type = "class")
# Confusion matrix
confusion_matrix <- table(Predicted = tree_pred, Actual = Carseats.test$High)
confusion_matrix
# Calculate test error rate
test_error_rate <- mean(tree_pred != Carseats.test$High)
cat("Test Error Rate:", test_error_rate, "\n")
cat("Test Accuracy:", 1 - test_error_rate, "\n")
getwd()
setwd("C:/Users/ktchi/OneDrive/Desktop/pstat197")
setwd("C:/Users/ktchi/OneDrive/Desktop/pstat197/vignette-image-classification-cnn")
reticulate::repl_python()
